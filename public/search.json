[
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/01_fastqc.html",
    "href": "04_data_analysis/001_snrnaseq_analysis/01_fastqc.html",
    "title": "Run FastQC on sample",
    "section": "",
    "text": "We can start by checking some QC metrics of the fasta files.\nTo count the number of fastq files we can use the following:\n\nCodels -lR /gluster/dri02/rdscw/shared/webber/Endo_10X/FASTQ/Set_2/ | grep --count \\.fastq.gz$ \n\n\nThere’s 144 in set 1, 244 in set 2, and 656 in set 3.\nIt’s a little graceless, but I’ll purl this script for set 1 and then manually create copies and change the array number and directory.\n\nCode#!/bin/bash\n\n#SBATCH -p c_highmem_dri1\n#SBATCH --job-name=fastqc_bbb\n#SBATCH --ntasks=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --array=1-144%144\n#SBATCH --mem-per-cpu=5000 # memory limit per core\n#####  #SBATCH --mem=96000 # memory limit per compute node for the job\n#SBATCH --time=1-00:00 # maximum job time in D-HH:MM\n#SBATCH --account=scw1329\n#SBATCH -o /scratch/c.mpmgb/hawk_output/%x_out_%A_%a_%J.txt\n#SBATCH -e /scratch/c.mpmgb/hawk_output/%x_err_%A_%a_%J.txt\n#SBATCH --mail-user Bernardo-HarringtonG@cardiff.ac.uk # email on fail\n#SBATCH --mail-type END,FAIL\n\necho \"*****************************************************************\"\necho \"All jobs in this array have:\"\necho \"- SLURM_ARRAY_JOB_ID: ${SLURM_ARRAY_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_COUNT: ${SLURM_ARRAY_TASK_COUNT}\"\necho \"- SLURM_ARRAY_TASK_MIN: ${SLURM_ARRAY_TASK_MIN}\"\necho \"- SLURM_ARRAY_TASK_MAX: ${SLURM_ARRAY_TASK_MAX}\"\necho \"This job in the array has:\"\necho \"- SLURM_JOB_ID: ${SLURM_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_ID: ${SLURM_ARRAY_TASK_ID}\"\necho \"Run on host: \"`hostname`\necho \"Number of threads (nproc): \"`nproc`\necho \"Total memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 1p`\necho \"Used memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 2p`\necho \"Free memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 3p`\necho \"Username: \"`whoami`\necho \"Started at: \"`date`\necho -e \"*****************************************************************\\n\"\n\n## FASTQ files\n## This if for batch 1 set 1\nINPUT_DIR_b1s1=\"/gluster/dri02/rdscw/shared/webber/Endo_10X/FASTQ/Set_1/211008_A00748_0157_AHT7TJDSX2_fastq_L2_3_4/\"\n## This is for batch 1 set 2\nINPUT_DIR_b1s2=\"/gluster/dri02/rdscw/shared/webber/Endo_10X/FASTQ/Set_2/\"\n## This is the directory for batch 2 (set 3)\nINPUT_DIR=\"/gluster/dri02/rdsmbh/shared/rdsmbh/230327_A00748_0368_AH5CTMDSX5_fastq/\"\n\nOUTPUT_DIR=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/01_fastqc/01_set1\"\nOUTPUT_DIR2=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/01_fastqc/02_set2\"\nOUTPUT_DIR3=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/01_fastqc/03_set3\"\n\n## Load FastQC module\nmodule load FastQC\n\n#-----------------------------------------------------------------------\n\nmkdir -p $OUTPUT_DIR\n\nN=${SLURM_ARRAY_TASK_ID}\n\nFASTQ_FILE=$(find $INPUT_DIR_b1s1 -mindepth 1 -maxdepth 1 -name '*_001.fastq.gz' | sort | tail -n+${N} | head -1)\nfastqc -o $OUTPUT_DIR1 -f fastq --noextract --quiet -t 1 $FASTQ_FILE\n \n# FASTQ_FILE=$(find $INPUT_DIR_b1s2 -mindepth 1 -maxdepth 3 -name '*_001.fastq.gz' | sort | tail -n+${N} | head -1)\n# fastqc -o $OUTPUT_DIR2 -f fastq --noextract --quiet -t 1 $FASTQ_FILE\n\n# FASTQ_FILE=$(find $INPUT_DIR -mindepth 1 -maxdepth 1 -name '*_001.fastq.gz' | sort | tail -n+${N} | head -1)\n# fastqc -o $OUTPUT_DIR3 -f fastq --noextract --quiet -t 1 $FASTQ_FILE\n\n\necho -e \"\\n*****************************************************************\"\necho \"Finished at: \"`date`\necho \"*****************************************************************\""
  },
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/02_multiqc.html",
    "href": "04_data_analysis/001_snrnaseq_analysis/02_multiqc.html",
    "title": "Run MultiQC",
    "section": "",
    "text": "MultiQC combines the fastqc reports together for us.\nYou can view the report for set 1 reads here, set 2 here and set 3 here.\nNote that the files containing a string like _I1_ are the indexes while strings like _R1_ are the reads. There’s a separate MultiQC report for each set and for the indexes and reads.\n\nCode#!/bin/bash\n\n#SBATCH -p c_highmem_dri1\n#SBATCH --job-name=multiqc_bbb\n#SBATCH --ntasks=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --time=1-00:00 # maximum job time in D-HH:MM\n#SBATCH --account=scw1329\n#SBATCH -o /scratch/c.mpmgb/hawk_output/%x_out_%A_%a_%J.txt\n#SBATCH -e /scratch/c.mpmgb/hawk_output/%x_err_%A_%a_%J.txt\n#SBATCH --mail-user Bernardo-HarringtonG@cardiff.ac.uk # email on fail\n#SBATCH --mail-type END,FAIL\n\necho \"*****************************************************************\"\necho \"All jobs in this array have:\"\necho \"- SLURM_ARRAY_JOB_ID: ${SLURM_ARRAY_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_COUNT: ${SLURM_ARRAY_TASK_COUNT}\"\necho \"- SLURM_ARRAY_TASK_MIN: ${SLURM_ARRAY_TASK_MIN}\"\necho \"- SLURM_ARRAY_TASK_MAX: ${SLURM_ARRAY_TASK_MAX}\"\necho \"This job in the array has:\"\necho \"- SLURM_JOB_ID: ${SLURM_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_ID: ${SLURM_ARRAY_TASK_ID}\"\necho \"Run on host: \"`hostname`\necho \"Number of threads (nproc): \"`nproc`\necho \"Total memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 1p`\necho \"Used memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 2p`\necho \"Free memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 3p`\necho \"Username: \"`whoami`\necho \"Started at: \"`date`\necho -e \"*****************************************************************\\n\"\n\n# Load module\nmodule load multiqc\n\n## collect MultiQC reports\nOUTPUT_DIR=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/02_multiqc/\"\n\n#-----------------------------------------------------------------------\n# FastQC runs\n\n## Endo 10X Vascular and Parenchymal fraction set 1 - 24 samples\nINPUT_DIR=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/01_fastqc/01_set1/\"\n## Endo 10X Vascular and Parenchymal fraction set 2 - 16 samples\nINPUT_DIR2=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/01_fastqc/02_set2/\"\n## Endo 10X Vascular and Parenchymal fraction set 3 - 40 samples\nINPUT_DIR3=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/01_fastqc/03_set3/\"\n\nmultiqc -o $OUTPUT_DIR\"01_set1_reads\" \\\n--filename \"fastqc_endo_10X_set1_reads\" \\\n--title \"FastQC endo 10X set1 reads\" \\\n--cl_config \"fastqc_config: { fastqc_theoretical_gc: hg38_txome }\" \\\n--module fastqc \\\n--force \\\n--interactive \\\n$INPUT_DIR\"\"*_R[1-2]_*_fastqc.zip\n\nmultiqc -o $OUTPUT_DIR\"01_set1_index\" \\\n--filename \"fastqc_endo_10X_set1_index\" \\\n--title \"FastQC endo 10X set1 index\" \\\n--cl_config \"fastqc_config: { fastqc_theoretical_gc: hg38_txome }\" \\\n--module fastqc \\\n--force \\\n--interactive \\\n$INPUT_DIR\"\"*_I[1-2]_*_fastqc.zip\n\nmultiqc -o $OUTPUT_DIR\"02_set2_reads\" \\\n--filename \"fastqc_endo_10X_set2_reads\" \\\n--title \"FastQC endo 10X set2 reads\" \\\n--cl_config \"fastqc_config: { fastqc_theoretical_gc: hg38_txome }\" \\\n--module fastqc \\\n--force \\\n--interactive \\\n$INPUT_DIR2\"\"*_R[1-2]_*_fastqc.zip\n\nmultiqc -o $OUTPUT_DIR\"02_set2_index\" \\\n--filename \"fastqc_endo_10X_set2_index\" \\\n--title \"FastQC endo 10X set2 index\" \\\n--cl_config \"fastqc_config: { fastqc_theoretical_gc: hg38_txome }\" \\\n--module fastqc \\\n--force \\\n--interactive \\\n$INPUT_DIR2\"\"*_I[1-2]_*_fastqc.zip\n\nmultiqc -o $OUTPUT_DIR\"03_set3_reads\" \\\n--filename \"fastqc_endo_10X_set3_reads\" \\\n--title \"FastQC endo 10X set3 reads\" \\\n--cl_config \"fastqc_config: { fastqc_theoretical_gc: hg38_txome }\" \\\n--module fastqc \\\n--force \\\n--interactive \\\n$INPUT_DIR3\"\"*_R[1-2]_*_fastqc.zip\n\nmultiqc -o $OUTPUT_DIR\"03_set3_index\" \\\n--filename \"fastqc_endo_10X_set3_index\" \\\n--title \"FastQC endo 10X set3 index\" \\\n--cl_config \"fastqc_config: { fastqc_theoretical_gc: hg38_txome }\" \\\n--module fastqc \\\n--force \\\n--interactive \\\n$INPUT_DIR3\"\"*_I[1-2]_*_fastqc.zip\n\necho -e \"\\n*****************************************************************\"\necho \"Finished at: \"`date`\necho \"*****************************************************************\""
  },
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/03_generate_cellranger_reference.html",
    "href": "04_data_analysis/001_snrnaseq_analysis/03_generate_cellranger_reference.html",
    "title": "Generate cellranger reference",
    "section": "",
    "text": "In order to run the cellranger pipeline one needs a reference genome for it to align to. 10X do provide a human reference, but it’s rather old at time of writing, so here we’ll generate a more recent one.\nNote that the initial download of the reference files are to be done on the login node. I’ll save them in the shared Webber dir on gluster (/gluster/dri02/rdscw/shared/webber/reference_genomes) in case others want to use it.\n\nCode#!/bin/bash\n\n#SBATCH -p c_highmem_dri1   ###c_highmem_dri1 ## dev, compute, htc, highmem\n#SBATCH --job-name=cellranger_ref_gen_bbb\n#SBATCH --ntasks=40\n#SBATCH --ntasks-per-node=40\n#### SBATCH --mem-per-cpu=30000 # memory limit per core\n#SBATCH --mem=50G # memory limit per compute node for the job\n#SBATCH --time=3-00:00 # maximum job time in D-HH:MM\n#SBATCH --account=scw1329\n#SBATCH -o /scratch/c.mpmgb/hawk_output/%x_out_%J.txt\n#SBATCH -e /scratch/c.mpmgb/hawk_output/%x_err_%J.txt\n#SBATCH --mail-user Bernardo-HarringtonG@cardiff.ac.uk # email on fail\n#SBATCH --mail-type END,FAIL\n\necho \"*****************************************************************\"\necho \"job ID: \"$SLURM_JOBID\necho \"job name: \"$SLURM_JOB_NAME\necho \"Run on host: \"`hostname`\necho \"Number of threads (nproc): \"`nproc`\necho \"Total memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 1p`\necho \"Used memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 2p`\necho \"Free memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 3p`\necho \"Username: \"`whoami`\necho \"Started at: \"`date`\necho -e \"*****************************************************************\\n\"\n\n#-----------------------------------------------------------------------\n\n## code from Cell Ranger (CR) website\n## modified to retrieve GRCh38 genome build from specific ensembl release\n## the default CR reference from July 2020 (refdata-gex-GRCh38-2020-A.tar.gz) is based on ensembl v98/Gencode v32\n## https://support.10xgenomics.com/single-cell-gene-expression/software/release-notes/build\n##\n## NOTE: run first download part on login node\n## pre-processing and cellranger mkref on compute node\n\n#-----------------------------------------------------------------------\n\n## CR v7.1.0\nCELL_RANGER=\"/scratch/c.mpmgb/tools/cellranger-7.1.0/bin/cellranger\"\n\n## which ensembl and gencode version\nENSEMBL_VER=\"109\"\nGENCODE_VER=\"43\"\n\n## store reference data\nREF_DIR=\"/gluster/dri02/rdscw/shared/webber/reference_genomes\"\ncd $REF_DIR\n\n# Genome metadata\ngenome=\"GRCh38\"\nversion=\"2023_\"${ENSEMBL_VER}\n\n# Set up source and build directories\nbuild=\"GRCh38_2023_\"${ENSEMBL_VER}\"_ensembl\"\nmkdir -p \"$build\"\n\n# Download source files if they do not exist in reference_sources/ folder\nsource=\"reference_sources_ensembl_\"${ENSEMBL_VER}\nmkdir -p \"$source\"\n\nfasta_url=\"http://ftp.ensembl.org/pub/release-\"${ENSEMBL_VER}\"/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz\"\nfasta_in=\"${source}/Homo_sapiens.GRCh38.dna.primary_assembly.fa\"\ngtf_url=\"http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_\"${GENCODE_VER}\"/gencode.v\"${GENCODE_VER}\".primary_assembly.annotation.gtf.gz\"\ngtf_in=\"${source}/gencode.v\"${GENCODE_VER}\".primary_assembly.annotation.gtf\"\n\n## compute node dir\nCOM_DIR=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/03_cellranger_reference\"\n\n#-----------------------------------------------------------------------\n## run on login node\n\n# if [ ! -f \"$fasta_in\" ]; then\n#     curl -sS \"$fasta_url\" | zcat &gt; \"$fasta_in\"\n# fi\n# if [ ! -f \"$gtf_in\" ]; then\n#     curl -sS \"$gtf_url\" | zcat &gt; \"$gtf_in\"\n# fi\n\n#-----------------------------------------------------------------------\n\n## copy the downloaded reference \n# cp -a ${REF_DIR}\"/.\" $COM_DIR\n\n## run on compute node\n\n# Move to the scratch dir\ncd $COM_DIR\n\n# Modify sequence headers in the Ensembl FASTA to match the file\n# \"GRCh38.primary_assembly.genome.fa\" from GENCODE. Unplaced and unlocalized\n# sequences such as \"KI270728.1\" have the same names in both versions.\n#\n# Input FASTA:\n#   &gt;1 dna:chromosome chromosome:GRCh38:1:1:248956422:1 REF\n#\n# Output FASTA:\n#   &gt;chr1 1\nfasta_modified=\"$build/$(basename \"$fasta_in\").modified\"\n# sed commands:\n# 1. Replace metadata after space with original contig name, as in GENCODE\n# 2. Add \"chr\" to names of autosomes and sex chromosomes\n# 3. Handle the mitochrondrial chromosome\ncat \"$fasta_in\" \\\n    | sed -E 's/^&gt;(\\S+).*/&gt;\\1 \\1/' \\\n    | sed -E 's/^&gt;([0-9]+|[XY]) /&gt;chr\\1 /' \\\n    | sed -E 's/^&gt;MT /&gt;chrM /' \\\n    &gt; \"$fasta_modified\"\n\n\n# Remove version suffix from transcript, gene, and exon IDs in order to match\n# previous Cell Ranger reference packages\n#\n# Input GTF:\n#     ... gene_id \"ENSG00000223972.5\"; ...\n# Output GTF:\n#     ... gene_id \"ENSG00000223972\"; gene_version \"5\"; ...\ngtf_modified=\"$build/$(basename \"$gtf_in\").modified\"\n# Pattern matches Ensembl gene, transcript, and exon IDs for human or mouse:\nID=\"(ENS(MUS)?[GTE][0-9]+)\\.([0-9]+)\"\ncat \"$gtf_in\" \\\n    | sed -E 's/gene_id \"'\"$ID\"'\";/gene_id \"\\1\"; gene_version \"\\3\";/' \\\n    | sed -E 's/transcript_id \"'\"$ID\"'\";/transcript_id \"\\1\"; transcript_version \"\\3\";/' \\\n    | sed -E 's/exon_id \"'\"$ID\"'\";/exon_id \"\\1\"; exon_version \"\\3\";/' \\\n    &gt; \"$gtf_modified\"\n\n\n# Define string patterns for GTF tags\n# NOTES:\n# - Since GENCODE release 31/M22 (Ensembl 97), the \"lincRNA\" and \"antisense\"\n#   biotypes are part of a more generic \"lncRNA\" biotype.\n# - These filters are relevant only to GTF files from GENCODE. The GTFs from\n#   Ensembl release 98 have the following differences:\n#   - The names \"gene_biotype\" and \"transcript_biotype\" are used instead of\n#     \"gene_type\" and \"transcript_type\".\n#   - Readthrough transcripts are present but are not marked with the\n#     \"readthrough_transcript\" tag.\n#   - Only the X chromosome versions of genes in the pseudoautosomal regions\n#     are present, so there is no \"PAR\" tag.\nBIOTYPE_PATTERN=\\\n\"(protein_coding|lncRNA|\\\nIG_C_gene|IG_D_gene|IG_J_gene|IG_LV_gene|IG_V_gene|\\\nIG_V_pseudogene|IG_J_pseudogene|IG_C_pseudogene|\\\nTR_C_gene|TR_D_gene|TR_J_gene|TR_V_gene|\\\nTR_V_pseudogene|TR_J_pseudogene)\"\nGENE_PATTERN=\"gene_type \\\"${BIOTYPE_PATTERN}\\\"\"\nTX_PATTERN=\"transcript_type \\\"${BIOTYPE_PATTERN}\\\"\"\nREADTHROUGH_PATTERN=\"tag \\\"readthrough_transcript\\\"\"\nPAR_PATTERN=\"tag \\\"PAR\\\"\"\n\n\n# Construct the gene ID allowlist. We filter the list of all transcripts\n# based on these criteria:\n#   - allowable gene_type (biotype)\n#   - allowable transcript_type (biotype)\n#   - no \"PAR\" tag (only present for Y chromosome PAR)\n#   - no \"readthrough_transcript\" tag\n# We then collect the list of gene IDs that have at least one associated\n# transcript passing the filters.\ncat \"$gtf_modified\" \\\n    | awk '$3 == \"transcript\"' \\\n    | grep -E \"$GENE_PATTERN\" \\\n    | grep -E \"$TX_PATTERN\" \\\n    | grep -Ev \"$READTHROUGH_PATTERN\" \\\n    | grep -Ev \"$PAR_PATTERN\" \\\n    | sed -E 's/.*(gene_id \"[^\"]+\").*/\\1/' \\\n    | sort \\\n    | uniq \\\n    &gt; \"${build}/gene_allowlist\"\n\n\necho \"Filter GTF...\"\n\n# Filter the GTF file based on the gene allowlist\ngtf_filtered=\"${build}/$(basename \"$gtf_in\").filtered\"\n# Copy header lines beginning with \"#\"\ngrep -E \"^#\" \"$gtf_modified\" &gt; \"$gtf_filtered\"\n# Filter to the gene allowlist\ngrep -Ff \"${build}/gene_allowlist\" \"$gtf_modified\" \\\n    &gt;&gt; \"$gtf_filtered\"\n    \n    \necho \"Run Cell Ranger mkref...\"  \n\n## Create reference package\n$CELL_RANGER mkref \\\n--ref-version=\"$version\" \\\n--genome=\"$genome\" \\\n--fasta=\"$fasta_modified\" \\\n--genes=\"$gtf_filtered\" \\\n--memgb=250 \\\n--nthreads=40"
  },
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/04_cellranger_count_set1.html",
    "href": "04_data_analysis/001_snrnaseq_analysis/04_cellranger_count_set1.html",
    "title": "Generate cellranger reference for set 1",
    "section": "",
    "text": "Set 1 contains the first 12 donors, 24 samples (12x P - parenchymal and 12x V - vascular fraction), which are independently sequenced of Set_2 (the remaining 16 samples from 8 donors). The sequencing was performed for Set_1 initially in Oxford, but there were some issues with index hopping and cleaning the data did not seem to work too well. So Set_1 was re-sequenced in Cardiff and the folder is: 211008_A00748_0157_AHT7TJDSX2_fastq_L2_3_4\nFor Set_2 the data was sequenced initially on one Illumina lane, but then more lanes were added for better coverage. So the FASTQ files across the 4 subdirs need to be combined as input for one sample. I think there were a couple of corner cases for those samples, one sample was of lower quality and not sequenced again, and one extra run of another sample basically had just one read. I think the script to run CellRanger for Set_2 should mention this and deal with it.\nDue to this funk with the samples I’ll keep them are seperate scripts for all three sets.\n\nCode#!/bin/bash\n\n#SBATCH -p c_highmem_dri1 ## dev, compute, htc, highmem\n#SBATCH --job-name=cellranger_count_set1\n#SBATCH --ntasks=40\n#SBATCH --ntasks-per-node=40\n#SBATCH --array=1-24%2\n##### #SBATCH --mem-per-cpu=8000 # memory limit per core\n#SBATCH --mem=340G # memory limit per compute node for the job\n#SBATCH --time=3-00:00 # maximum job time in D-HH:MM\n#SBATCH --account=scw1329\n#SBATCH -o /scratch/c.mpmgb/hawk_output/%x_out_%A_%a_%J.txt\n#SBATCH -e /scratch/c.mpmgb/hawk_output/%x_err_%A_%a_%J.txt\n#SBATCH --mail-user Bernardo-HarringtonG@cardiff.ac.uk # email on fail\n#SBATCH --mail-type END,FAIL\n\necho \"*****************************************************************\"\necho \"All jobs in this array have:\"\necho \"- SLURM_ARRAY_JOB_ID: ${SLURM_ARRAY_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_COUNT: ${SLURM_ARRAY_TASK_COUNT}\"\necho \"- SLURM_ARRAY_TASK_MIN: ${SLURM_ARRAY_TASK_MIN}\"\necho \"- SLURM_ARRAY_TASK_MAX: ${SLURM_ARRAY_TASK_MAX}\"\necho \"This job in the array has:\"\necho \"- SLURM_JOB_ID: ${SLURM_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_ID: ${SLURM_ARRAY_TASK_ID}\"\necho \"Run on host: \"`hostname`\necho \"Number of threads (nproc): \"`nproc`\necho \"Total memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 1p`\necho \"Used memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 2p`\necho \"Free memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 3p`\necho \"Username: \"`whoami`\necho \"Started at: \"`date`\necho -e \"*****************************************************************\\n\"\n\n#-----------------------------------------------------------------------\n\n## FASTQ files, set 1, 24 samples, sequenced in Cardiff\n## NOTE, R2 length is 150bp, complete length will be used by default\n## alternatively, reads could be trimmed  with Cell Ranger option --r2-length=90\nINPUT_DIR=\"/gluster/dri02/rdscw/shared/webber/Endo_10X/FASTQ/Set_1/211008_A00748_0157_AHT7TJDSX2_fastq_L2_3_4/\"\n\n## results\nOUTPUT_DIR=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/04_cellranger_count/01_set1\"\n\n## original sample IDs, correpond to FASTQ file names\nSAMPLE_ID_FILE=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/90_sample_info/samples_set1_IDs.txt\"\n\n## corresponding new sample names to be set by --id\n## NOTE: some samples will be de-swapped, as they were wrongly labelled during library prep in Oxford\nSAMPLE_ID_NEW_FILE=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/90_sample_info/samples_set1_IDs_swap.txt\"\n\n## CR executable\nCELL_RANGER=\"/scratch/c.mpmgb/tools/cellranger-7.1.0/bin/cellranger\"\n\n## CR reference\n## pre-computed and downloaded from CR website as is (refdata-gex-GRCh38-2020-A.tar.gz)\n## based on ensembl v98/gencode v32\n## CR_REF=\"/scratch/c.mpmgb/Tools/CellRanger/CellRanger_references/refdata-gex-GRCh38-2020-A\"\n## updated CR reference based on ensembl v109 (Gencode v43)\n## from get_cellranger_reference.sh\nCR_REF=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/03_cellranger_reference/GRCh38\"\n\n#-----------------------------------------------------------------------\n# Cell Ranger count\n\nmkdir -p $OUTPUT_DIR\n\nN=${SLURM_ARRAY_TASK_ID}\n\nSAMPLE_ID=$(cat $SAMPLE_ID_FILE | tail -n+${N} | head -1)\nSAMPLE_ID_NEW=$(cat $SAMPLE_ID_NEW_FILE | tail -n+${N} | head -1)\n\necho \"Input dir: \"$INPUT_DIR\necho \"Sample: \"$SAMPLE_ID\necho \"Sample new: \"$SAMPLE_ID_NEW\n\ncd $OUTPUT_DIR\n\n$CELL_RANGER count --id=$SAMPLE_ID_NEW \\\n--fastqs=$INPUT_DIR \\\n--sample=$SAMPLE_ID \\\n--transcriptome=$CR_REF \\\n--localcores=40 \\\n--localmem=320 \\\n--include-introns=true \\\n--no-bam\n\n## optional:\n## R2 length is longer (150bp) than usually recommended/required (90bp)\n## --r2-length=90\n\necho -e \"\\n*****************************************************************\"\necho \"Finished at: \"`date`\necho \"*****************************************************************\""
  },
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/05_cellranger_count_set2.html",
    "href": "04_data_analysis/001_snrnaseq_analysis/05_cellranger_count_set2.html",
    "title": "Generate cellranger reference for set 2",
    "section": "",
    "text": "This is for set 2:\n\nCode#!/bin/bash\n\n#SBATCH -p c_highmem_dri1 ## dev, compute, htc, highmem\n#SBATCH --job-name=cellranger_count_set2\n#SBATCH --ntasks=40\n#SBATCH --ntasks-per-node=40\n#SBATCH --array=1-16%2\n##### #SBATCH --mem-per-cpu=8000 # memory limit per core\n#SBATCH --mem=340G # memory limit per compute node for the job\n#SBATCH --time=3-00:00 # maximum job time in D-HH:MM\n#SBATCH --account=scw1329\n#SBATCH -o /scratch/c.mpmgb/hawk_output/%x_out_%A_%a_%J.txt\n#SBATCH -e /scratch/c.mpmgb/hawk_output/%x_err_%A_%a_%J.txt\n#SBATCH --mail-user Bernardo-HarringtonG@cardiff.ac.uk # email on fail\n#SBATCH --mail-type END,FAIL\n\necho \"*****************************************************************\"\necho \"All jobs in this array have:\"\necho \"- SLURM_ARRAY_JOB_ID: ${SLURM_ARRAY_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_COUNT: ${SLURM_ARRAY_TASK_COUNT}\"\necho \"- SLURM_ARRAY_TASK_MIN: ${SLURM_ARRAY_TASK_MIN}\"\necho \"- SLURM_ARRAY_TASK_MAX: ${SLURM_ARRAY_TASK_MAX}\"\necho \"This job in the array has:\"\necho \"- SLURM_JOB_ID: ${SLURM_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_ID: ${SLURM_ARRAY_TASK_ID}\"\necho \"Run on host: \"`hostname`\necho \"Number of threads (nproc): \"`nproc`\necho \"Total memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 1p`\necho \"Used memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 2p`\necho \"Free memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 3p`\necho \"Username: \"`whoami`\necho \"Started at: \"`date`\necho -e \"*****************************************************************\\n\"\n\n\n## FASTQ files, set 2 with 16 samples, data from 4 runs, sequenced in Oxford\n## NOTE, V_19, only sequenced in 1 run (INPUT_DIR_1)\n## NOTE, V_20, 1 run (INPUT_DIR_2) only with a single read, skip that run\n## handled via if statement below\nINPUT_DIR_1=\"/gluster/dri02/rdscw/shared/webber/Endo_10X/FASTQ/Set_2/210707_A00711_0393_BHCLTKDSX2/FASTQ/\"\nINPUT_DIR_2=\"/gluster/dri02/rdscw/shared/webber/Endo_10X/FASTQ/Set_2/210721_A00711_0400_BHF2YWDSX2/FASTQ/\"\nINPUT_DIR_3=\"/gluster/dri02/rdscw/shared/webber/Endo_10X/FASTQ/Set_2/210728_A00711_0405_BHF5JLDSX2/FASTQ/\"\nINPUT_DIR_4=\"/gluster/dri02/rdscw/shared/webber/Endo_10X/FASTQ/Set_2/210901_A00711_0420_AHGJJLDSX2/FASTQ/\"\n\n## results\nOUTPUT_DIR=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/04_cellranger_count/02_set2\"\n\n## original sample IDs, correpond to FASTQ file names\nSAMPLE_ID_FILE=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/90_sample_info/samples_set2_4_runs.txt\"\n\n## corresponding new sample names to be set by --id\nSAMPLE_ID_NEW_FILE=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/90_sample_info/samples_set2_rename.txt\"\n\n## CR executable\nCELL_RANGER=\"/scratch/c.mpmgb/tools/cellranger-7.1.0/bin/cellranger\"\n\n## CR reference\n## pre-computed and downloaded from CR website as is (refdata-gex-GRCh38-2020-A.tar.gz)\n## based on ensembl v98/gencode v32\n## CR_REF=\"/scratch/c.mpmfw/Tools/CellRanger/CellRanger_references/refdata-gex-GRCh38-2020-A\"\n## updated CR reference based on ensembl v108 (Gencode v42)\n## from get_cellranger_reference.sh\nCR_REF=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/03_cellranger_reference/GRCh38\"\n\n\n#-----------------------------------------------------------------------\n# Cell Ranger count\n\nmkdir -p $OUTPUT_DIR\n\nN=${SLURM_ARRAY_TASK_ID}\n\nSAMPLE_ID=$(cat $SAMPLE_ID_FILE | tail -n+${N} | head -1)\nSAMPLE_ID_NEW=$(cat $SAMPLE_ID_NEW_FILE | tail -n+${N} | head -1)\n\necho \"Input dir(s): \"$INPUT_DIR_1\", \"$INPUT_DIR_2\", \"$INPUT_DIR_3\", \"$INPUT_DIR_4\necho \"Sample: \"$SAMPLE_ID\necho \"Sample new: \"$SAMPLE_ID_NEW\n\ncd $OUTPUT_DIR\n\nif [[ \"$SAMPLE_ID_NEW\" == \"V_19\" ]]\nthen\n    $CELL_RANGER count --id=$SAMPLE_ID_NEW \\\n    --fastqs=$INPUT_DIR_1 \\\n    --sample=$SAMPLE_ID \\\n    --transcriptome=$CR_REF \\\n    --localcores=40 \\\n    --localmem=330 \\\n    --include-introns=true \\\n    --no-bam\nelif [[ \"$SAMPLE_ID_NEW\" == \"V_20\" ]]\nthen\n    $CELL_RANGER count --id=$SAMPLE_ID_NEW \\\n    --fastqs=$INPUT_DIR_1,$INPUT_DIR_3,$INPUT_DIR_4 \\\n    --sample=$SAMPLE_ID \\\n    --transcriptome=$CR_REF \\\n    --localcores=40 \\\n    --localmem=330 \\\n    --include-introns=true \\\n    --no-bam\nelse\n    $CELL_RANGER count --id=$SAMPLE_ID_NEW \\\n    --fastqs=$INPUT_DIR_1,$INPUT_DIR_2,$INPUT_DIR_3,$INPUT_DIR_4 \\\n    --sample=$SAMPLE_ID \\\n    --transcriptome=$CR_REF \\\n    --localcores=40 \\\n    --localmem=330 \\\n    --include-introns=true \\\n    --no-bam\nfi\n\n## optional:\n## R2 length is longer (151bp) than usually recommended/required (90bp)\n## --r2-length=90\n\necho -e \"\\n*****************************************************************\"\necho \"Finished at: \"`date`\necho \"*****************************************************************\""
  },
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/06_cellranger_count_set3.html",
    "href": "04_data_analysis/001_snrnaseq_analysis/06_cellranger_count_set3.html",
    "title": "Generate cellranger reference for set 3",
    "section": "",
    "text": "This is for set 3\nNote that the sample IDs are in the fastq file names. The following command was used to extract them:\nfind 230327_A00748_0368_AH5CTMDSX5_fastq/ -name '*.fastq.gz' | grep -oP '(?&lt;=/)\\w{20}' | cut -c4-7 | sort | uniq  &gt; samples_set3.txt\nThere are also some Undeterimed files that I’m unsure of, but I manually added the missing bit of the string for that one."
  },
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/06_cellranger_count_set3.html#note",
    "href": "04_data_analysis/001_snrnaseq_analysis/06_cellranger_count_set3.html#note",
    "title": "Generate cellranger reference for set 3",
    "section": "\n1 Note",
    "text": "1 Note\nSample P_39 gave an error, it seems the fastq files are all empty. Spoke to Jo and she can’t see anything obviously wrong on her end, so it may be that the sample was just not present due to a pipetting error perhaps\n\nCode#!/bin/bash\n\n#SBATCH -p c_highmem_dri1 ## dev, compute, htc, highmem\n#SBATCH --job-name=cellranger_count_set3\n#SBATCH --ntasks=40\n#SBATCH --ntasks-per-node=40\n#SBATCH --array=1-40%2\n##### #SBATCH --mem-per-cpu=8000 # memory limit per core\n#SBATCH --mem=340G # memory limit per compute node for the job\n#SBATCH --time=2-10:00 # maximum job time in D-HH:MM\n#SBATCH --account=scw1329\n#SBATCH -o /scratch/c.mpmgb/hawk_output/%x_out_%A_%a_%J.txt\n#SBATCH -e /scratch/c.mpmgb/hawk_output/%x_err_%A_%a_%J.txt\n#SBATCH --mail-user Bernardo-HarringtonG@cardiff.ac.uk # email on fail\n#SBATCH --mail-type END,FAIL\n\necho \"*****************************************************************\"\necho \"All jobs in this array have:\"\necho \"- SLURM_ARRAY_JOB_ID: ${SLURM_ARRAY_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_COUNT: ${SLURM_ARRAY_TASK_COUNT}\"\necho \"- SLURM_ARRAY_TASK_MIN: ${SLURM_ARRAY_TASK_MIN}\"\necho \"- SLURM_ARRAY_TASK_MAX: ${SLURM_ARRAY_TASK_MAX}\"\necho \"This job in the array has:\"\necho \"- SLURM_JOB_ID: ${SLURM_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_ID: ${SLURM_ARRAY_TASK_ID}\"\necho \"Run on host: \"`hostname`\necho \"Number of threads (nproc): \"`nproc`\necho \"Total memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 1p`\necho \"Used memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 2p`\necho \"Free memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 3p`\necho \"Username: \"`whoami`\necho \"Started at: \"`date`\necho -e \"*****************************************************************\\n\"\n\n\n## FASTQ files, set 2 with 16 samples, data from 4 runs, sequenced in Oxford\n## NOTE, V_19, only sequenced in 1 run (INPUT_DIR_1)\n## NOTE, V_20, 1 run (INPUT_DIR_2) only with a single read, skip that run\n## handled via if statement below\nINPUT_DIR=\"/gluster/dri02/rdsmbh/shared/rdsmbh/230327_A00748_0368_AH5CTMDSX5_fastq/\"\n\n## results\nOUTPUT_DIR=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/04_cellranger_count/03_set3\"\n\n## original sample IDs, correpond to FASTQ file names\nSAMPLE_ID_FILE=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/90_sample_info/samples_set3.txt\"\n\n## CR executable\nCELL_RANGER=\"/scratch/c.mpmgb/tools/cellranger-7.1.0/bin/cellranger\"\n\n## CR reference\n## pre-computed and downloaded from CR website as is (refdata-gex-GRCh38-2020-A.tar.gz)\n## based on ensembl v98/gencode v32\n## CR_REF=\"/scratch/c.mpmfw/Tools/CellRanger/CellRanger_references/refdata-gex-GRCh38-2020-A\"\n## updated CR reference based on ensembl v108 (Gencode v42)\n## from get_cellranger_reference.sh\nCR_REF=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/03_cellranger_reference/GRCh38\"\n\n\n#-----------------------------------------------------------------------\n# Cell Ranger count\n\nmkdir -p $OUTPUT_DIR\n\nN=${SLURM_ARRAY_TASK_ID}\n\nSAMPLE_ID=$(cat $SAMPLE_ID_FILE | tail -n+${N} | head -1)\n# Get the sample ID string after the first \"_\"\nSAMPLE_ID_NEW=\"${SAMPLE_ID#*_}\"\n\necho \"Input dir: \"$INPUT_DIR\necho \"Sample: \"$SAMPLE_ID\necho \"Sample new: \"$SAMPLE_ID_NEW\n\ncd $OUTPUT_DIR\n\n$CELL_RANGER count --id=$SAMPLE_ID_NEW \\\n--fastqs=$INPUT_DIR \\\n--sample=$SAMPLE_ID \\\n--transcriptome=$CR_REF \\\n--localcores=40 \\\n--localmem=330 \\\n--include-introns=true \\\n--no-bam\n\n## optional:\n## R2 length is longer (151bp) than usually recommended/required (90bp)\n## --r2-length=90\n\necho -e \"\\n*****************************************************************\"\necho \"Finished at: \"`date`\necho \"*****************************************************************\"\n\n\nOne of the many outputs of interest is the web_summary.html report files that have include various metrics worth checking. I’m not keen to add the whole output to the Git repo due to the file size, so I’ll just add these files for now.\nNote that there’s a also a web_summary.html in the SC_RNA_COUNTER_CS folder, but I don’t want that one here so I’ll also remove those.\n\nCode# get the file paths for all the \"web_summary.html\" files and save them to a file\nfind 03_data/990_processed_data/001_snrnaseq/04_cellranger_count/ -name \"web_summary.html\" &gt; web_summary_files.txt\n\n# the line length for the summary in the SC_RNA_COUNTER_CS dir is longer:\nawk '{print length}' web_summary_files.txt | sort -n | uniq -c\n# so we'll remove lines based on their length\nawk 'length &lt;= max_length' max_length=\"140\" web_summary_files.txt &gt; web_summary_files.txt\n# prepend \"git add \" to the file lines\nsed 's/^/git add /' web_summary_files_clean.txt &gt; web_summary_files_git.sh\n\n# run the file\nsh web_summary_files_git.sh\n# clean up\nrm web_summary_files.txt web_summary_files_clean.txt web_summary_files_git.sh"
  },
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/07_cellranger_aggr.html",
    "href": "04_data_analysis/001_snrnaseq_analysis/07_cellranger_aggr.html",
    "title": "Aggregate cellranger count reports",
    "section": "",
    "text": "cellranger count produces a report per sample, but it’s more useful to aggregate these results into one, so we have cellranger aggr for this.\nThis requires a 2 column CSV file (headers of sample_id,molecule_h5) with samples ID and the path to the molecule_info.h5 file.\nFrom the MultiQC reports, it seems the lastest batch if of better quality than the first two, so I’ll try using aggr on each set separately, and all data combined.\nYou can find these combined report for all samples here, set 1 here, set 2 here, and set 3 here.\n\nCode# list the cellranger count output directories\nfind /scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/04_cellranger_count/ -maxdepth 2 -mindepth 2 -type d &gt; cellranger_ag.txt \n\n# use the last directory in the path as the sample id\nawk -F'/' '{print $NF \",\" $0}' cellranger_ag.txt &gt; cellranger_ag2.txt\n\n# append \"outs/filtered_gene_bc_matrices\" to file paths\nsed \"s|$|/outs/molecule_info.h5|\" cellranger_ag2.txt &gt; cellranger_ag3.txt\n\n# remove the undetermined sample and P_39\ngrep -v \"Undetermined\" cellranger_ag3.txt &gt; cellranger_ag4.txt\ngrep -v \"P_39\" cellranger_ag4.txt &gt; cellranger_ag5.txt\n\n# separate out the sets\ngrep \"01_set1\" cellranger_ag5.txt &gt; cellranger_ag_set1.txt\ngrep \"02_set2\" cellranger_ag5.txt &gt; cellranger_ag_set2.txt\ngrep \"03_set3\" cellranger_ag5.txt &gt; cellranger_ag_set3.txt\n\n# add the table headers\nawk -v line=\"sample_id,molecule_h5\" 'BEGIN{print line}{print}' cellranger_ag_set1.txt &gt; cellranger_aggr_set1.csv\nawk -v line=\"sample_id,molecule_h5\" 'BEGIN{print line}{print}' cellranger_ag_set2.txt &gt; cellranger_aggr_set2.csv\nawk -v line=\"sample_id,molecule_h5\" 'BEGIN{print line}{print}' cellranger_ag_set3.txt &gt; cellranger_aggr_set3.csv\nawk -v line=\"sample_id,molecule_h5\" 'BEGIN{print line}{print}' cellranger_ag5.txt &gt; cellranger_aggr_all_sets.csv\n\n# make a file that has the file paths to use in the array job\necho \"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/05_cellranger_aggr/cellranger_aggr_set1.csv\" &gt; cellranger_aggr_csvs.txt\necho \"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/05_cellranger_aggr/cellranger_aggr_set2.csv\" &gt;&gt; cellranger_aggr_csvs.txt\necho \"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/05_cellranger_aggr/cellranger_aggr_set3.csv\" &gt;&gt; cellranger_aggr_csvs.txt\necho \"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/05_cellranger_aggr/cellranger_aggr_all_sets.csv\" &gt;&gt; cellranger_aggr_csvs.txt\n\n# clean up\nrm cellranger_ag.txt cellranger_ag2.txt cellranger_ag3.txt cellranger_ag_set1.txt cellranger_ag_set2.txt cellranger_ag_set3.txt cellranger_ag4.txt cellranger_ag5.txt\n\n\n\nCode#!/bin/bash\n\n#SBATCH -p c_vhighmem_dri1 ## dev, compute, htc, highmem\n#SBATCH --job-name=cellranger_aggr\n#SBATCH --ntasks=40\n#SBATCH --ntasks-per-node=40\n#SBATCH --array=1-4%2\n##### #SBATCH --mem-per-cpu=8000 # memory limit per core\n#SBATCH --mem=640G # memory limit per compute node for the job\n#SBATCH --time=2-10:00 # maximum job time in D-HH:MM\n#SBATCH --account=scw1329\n#SBATCH -o /scratch/c.mpmgb/hawk_output/%x_out_%A_%a_%J.txt\n#SBATCH -e /scratch/c.mpmgb/hawk_output/%x_err_%A_%a_%J.txt\n#SBATCH --mail-user Bernardo-HarringtonG@cardiff.ac.uk # email on fail\n#SBATCH --mail-type END,FAIL\n\necho \"*****************************************************************\"\necho \"All jobs in this array have:\"\necho \"- SLURM_ARRAY_JOB_ID: ${SLURM_ARRAY_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_COUNT: ${SLURM_ARRAY_TASK_COUNT}\"\necho \"- SLURM_ARRAY_TASK_MIN: ${SLURM_ARRAY_TASK_MIN}\"\necho \"- SLURM_ARRAY_TASK_MAX: ${SLURM_ARRAY_TASK_MAX}\"\necho \"This job in the array has:\"\necho \"- SLURM_JOB_ID: ${SLURM_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_ID: ${SLURM_ARRAY_TASK_ID}\"\necho \"Run on host: \"`hostname`\necho \"Number of threads (nproc): \"`nproc`\necho \"Total memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 1p`\necho \"Used memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 2p`\necho \"Free memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 3p`\necho \"Username: \"`whoami`\necho \"Started at: \"`date`\necho -e \"*****************************************************************\\n\"\n\n\n## path to input csvs with samples IDs and paths to cellranger count outputs\nINPUT_CSVS=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/05_cellranger_aggr/cellranger_aggr_csvs.txt\"\n\n## results\nOUTPUT_DIR=\"/scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/05_cellranger_aggr\"\n\n## CR executable\nCELL_RANGER=\"/scratch/c.mpmgb/tools/cellranger-7.1.0/bin/cellranger\"\n\n\n#-----------------------------------------------------------------------\n# Cell Ranger aggr\n\nmkdir -p $OUTPUT_DIR\n\nN=${SLURM_ARRAY_TASK_ID}\n\nINPUT_CSV=$(cat $INPUT_CSVS | tail -n+${N} | head -1)\n# Subset to last part of the file path\nINPUT_CSV_NAME=\"${INPUT_CSV##*/}\"\n# Subset string to first \".\"\nSAVE_DIR=\"${INPUT_CSV_NAME%%.*}\"\n\necho \"Input CSV: \"$INPUT_CSV\necho \"Save dir: \"$SAVE_DIR\n\ncd $OUTPUT_DIR\n\n$CELL_RANGER aggr --id=$SAVE_DIR \\\n--csv=$INPUT_CSV\n\necho -e \"\\n*****************************************************************\"\necho \"Finished at: \"`date`\necho \"*****************************************************************\""
  },
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/08_scflow.html",
    "href": "04_data_analysis/001_snrnaseq_analysis/08_scflow.html",
    "title": "Run scflow",
    "section": "",
    "text": "To run scflow we need a manifest tsv file where the first column is a unique sample ID and the second column is the file path to the directory that has the barcodes.tsv, genes.tsv and matrix.mtx files.\nI’m assuming we want to use the filtered gene-barcode matrices in MEX format as opposed to the raw files.\n\nCode# list the cellranger count output directories\nfind /scratch/scw1329/gmbh/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/04_cellranger_count/ -maxdepth 2 -mindepth 2 -type d &gt; scflow_manifest.txt\n\n# use the last direcotry in the path as the sample id\nawk -F'/' '{print $NF \"\\t\" $0}' scflow_manifest.txt &gt; scflow_manifest2.txt\n\n# append \"outs/filtered_gene_bc_matrices\" to file paths\nsed \"s|$|/outs/filtered_feature_bc_matrix|\" scflow_manifest2.txt &gt; scflow_manifest3.txt\n\n# remove the undetermined sample and P_39\ngrep -v \"Undetermined\" scflow_manifest3.txt &gt; scflow_manifest4.txt\ngrep -v \"P_39\" scflow_manifest4.txt &gt; scflow_manifest5.txt\n\n# add the table headers\nawk -v line=\"key\\tfilepath\" 'BEGIN{print line}{print}' scflow_manifest5.txt &gt; scflow_manifest.tsv\n\n# clean up\nrm scflow_manifest.txt scflow_manifest2.txt scflow_manifest3.txt scflow_manifest4.txt scflow_manifest5.txt\n\n\n\nCodenextflow run combiz/nf-core-scflow -r dev-nf -profile test,docker"
  },
  {
    "objectID": "04_data_analysis/990_code_libraries/01_r-packages-used.html",
    "href": "04_data_analysis/990_code_libraries/01_r-packages-used.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView SourceHere is we install/load all the packages we use in this project.\n\nCode# create library calls for renv\nlibrary_calls &lt;- paste0(\"library(\", c(pkg, pkg_bioconductor), \")\")\nwrite_lines(library_calls, here(\"04_data_analysis/990_code_libraries/02_library-calls-for-renv.R\"))\n\n\n\nCoderm(pkg, pkg_bioconductor, sort_packages)"
  },
  {
    "objectID": "06_dissemination/03_website/01_data-analysis.html",
    "href": "06_dissemination/03_website/01_data-analysis.html",
    "title": "Data Analysis Pipeline",
    "section": "",
    "text": "This section of the site houses the data analysis performed."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BBB in AD",
    "section": "",
    "text": "This is a Quarto website that outlines the analysis pipeline of this project."
  },
  {
    "objectID": "index.html#renv",
    "href": "index.html#renv",
    "title": "BBB in AD",
    "section": "\n1.1 renv",
    "text": "1.1 renv\nNote that the project used renv to manage the R packages used. When you first clone the repo to your local machine, you’ll need to run renv::restore() in R for it to establish all the packages needed."
  },
  {
    "objectID": "index.html#website-execution-caching",
    "href": "index.html#website-execution-caching",
    "title": "BBB in AD",
    "section": "\n1.2 Website execution caching",
    "text": "1.2 Website execution caching\nNote that the website uses caching to save the results of the scripts to the _freeze directory.\nThis is helpful as it allows the website to be built quickly after the first build, but it can be tricky as it will only rerun a given script if it sees a change in that script. So, if you change an earlier script that would alter the inputs of later scripts, it wouldn’t rerun those script as the code hadn’t changed, and so they wouldn’t change on the website.\nIf you run into any issues with this, just delete the _freeze directory and build the website again."
  }
]