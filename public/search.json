[
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/01_fastqc.html",
    "href": "04_data_analysis/001_snrnaseq_analysis/01_fastqc.html",
    "title": "Run FastQC on sample",
    "section": "",
    "text": "We can start by checking some QC metrics of the fasta files.\nTo count the number of fastq files we can use the following:\n\nCodels -lR /gluster/dri02/rdscw/shared/webber/Endo_10X/FASTQ/Set_2/ | grep --count \\.fastq.gz$ \n\n\nThere’s 144 in set 1, 244 in set 2, and 656 in set 3.\nIt’s a little graceless, but I’ll purl this script for set 1 and then manually create copies and change the array number and directory.\n\nCode#!/bin/bash\n\n#SBATCH -p c_highmem_dri1\n#SBATCH --job-name=fastqc_bbb\n#SBATCH --ntasks=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --array=1-144%144\n#SBATCH --mem-per-cpu=5000 # memory limit per core\n#####  #SBATCH --mem=96000 # memory limit per compute node for the job\n#SBATCH --time=1-00:00 # maximum job time in D-HH:MM\n#SBATCH --account=scw1329\n#SBATCH -o /scratch/c.mpmgb/hawk_output/%x_out_%A_%a_%J.txt\n#SBATCH -e /scratch/c.mpmgb/hawk_output/%x_err_%A_%a_%J.txt\n#SBATCH --mail-user Bernardo-HarringtonG@cardiff.ac.uk # email on fail\n#SBATCH --mail-type END,FAIL\n\necho \"*****************************************************************\"\necho \"All jobs in this array have:\"\necho \"- SLURM_ARRAY_JOB_ID: ${SLURM_ARRAY_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_COUNT: ${SLURM_ARRAY_TASK_COUNT}\"\necho \"- SLURM_ARRAY_TASK_MIN: ${SLURM_ARRAY_TASK_MIN}\"\necho \"- SLURM_ARRAY_TASK_MAX: ${SLURM_ARRAY_TASK_MAX}\"\necho \"This job in the array has:\"\necho \"- SLURM_JOB_ID: ${SLURM_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_ID: ${SLURM_ARRAY_TASK_ID}\"\necho \"Run on host: \"`hostname`\necho \"Number of threads (nproc): \"`nproc`\necho \"Total memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 1p`\necho \"Used memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 2p`\necho \"Free memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 3p`\necho \"Username: \"`whoami`\necho \"Started at: \"`date`\necho -e \"*****************************************************************\\n\"\n\n## FASTQ files\n## This if for batch 1 set 1\nINPUT_DIR_b1s1=\"/gluster/dri02/rdscw/shared/webber/Endo_10X/FASTQ/Set_1/211008_A00748_0157_AHT7TJDSX2_fastq_L2_3_4/\"\n## This is for batch 1 set 2\nINPUT_DIR_b1s2=\"/gluster/dri02/rdscw/shared/webber/Endo_10X/FASTQ/Set_2/\"\n## This is the directory for batch 2 (set 3)\nINPUT_DIR=\"/gluster/dri02/rdsmbh/shared/rdsmbh/230327_A00748_0368_AH5CTMDSX5_fastq/\"\n\nOUTPUT_DIR=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/01_fastqc/01_set1\"\nOUTPUT_DIR2=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/01_fastqc/02_set2\"\nOUTPUT_DIR3=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/01_fastqc/03_set3\"\n\n## Load FastQC module\nmodule load FastQC\n\n#-----------------------------------------------------------------------\n\nmkdir -p $OUTPUT_DIR\n\nN=${SLURM_ARRAY_TASK_ID}\n\nFASTQ_FILE=$(find $INPUT_DIR_b1s1 -mindepth 1 -maxdepth 1 -name '*_001.fastq.gz' | sort | tail -n+${N} | head -1)\nfastqc -o $OUTPUT_DIR1 -f fastq --noextract --quiet -t 1 $FASTQ_FILE\n \n# FASTQ_FILE=$(find $INPUT_DIR_b1s2 -mindepth 1 -maxdepth 3 -name '*_001.fastq.gz' | sort | tail -n+${N} | head -1)\n# fastqc -o $OUTPUT_DIR2 -f fastq --noextract --quiet -t 1 $FASTQ_FILE\n\n# FASTQ_FILE=$(find $INPUT_DIR -mindepth 1 -maxdepth 1 -name '*_001.fastq.gz' | sort | tail -n+${N} | head -1)\n# fastqc -o $OUTPUT_DIR3 -f fastq --noextract --quiet -t 1 $FASTQ_FILE\n\n\necho -e \"\\n*****************************************************************\"\necho \"Finished at: \"`date`\necho \"*****************************************************************\""
  },
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/02_multiqc.html",
    "href": "04_data_analysis/001_snrnaseq_analysis/02_multiqc.html",
    "title": "Run MultiQC",
    "section": "",
    "text": "MultiQC combines the fastqc reports together for us.\nYou can view the report for set 1 reads here, set 2 here and set 3 here.\nNote that the files containing a string like _I1_ are the indexes while strings like _R1_ are the reads.\n\nCode#!/bin/bash\n\n#SBATCH -p c_highmem_dri1\n#SBATCH --job-name=multiqc_bbb\n#SBATCH --ntasks=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --time=1-00:00 # maximum job time in D-HH:MM\n#SBATCH --account=scw1329\n#SBATCH -o /scratch/c.mpmgb/hawk_output/%x_out_%A_%a_%J.txt\n#SBATCH -e /scratch/c.mpmgb/hawk_output/%x_err_%A_%a_%J.txt\n#SBATCH --mail-user Bernardo-HarringtonG@cardiff.ac.uk # email on fail\n#SBATCH --mail-type END,FAIL\n\necho \"*****************************************************************\"\necho \"All jobs in this array have:\"\necho \"- SLURM_ARRAY_JOB_ID: ${SLURM_ARRAY_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_COUNT: ${SLURM_ARRAY_TASK_COUNT}\"\necho \"- SLURM_ARRAY_TASK_MIN: ${SLURM_ARRAY_TASK_MIN}\"\necho \"- SLURM_ARRAY_TASK_MAX: ${SLURM_ARRAY_TASK_MAX}\"\necho \"This job in the array has:\"\necho \"- SLURM_JOB_ID: ${SLURM_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_ID: ${SLURM_ARRAY_TASK_ID}\"\necho \"Run on host: \"`hostname`\necho \"Number of threads (nproc): \"`nproc`\necho \"Total memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 1p`\necho \"Used memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 2p`\necho \"Free memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 3p`\necho \"Username: \"`whoami`\necho \"Started at: \"`date`\necho -e \"*****************************************************************\\n\"\n\n# Load module\nmodule load multiqc\n\n## collect MultiQC reports\nOUTPUT_DIR=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/02_multiqc/\"\n\n#-----------------------------------------------------------------------\n# FastQC runs\n\n## Endo 10X Vascular and Parenchymal fraction set 1 - 24 samples\nINPUT_DIR=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/01_fastqc/01_set1/\"\n## Endo 10X Vascular and Parenchymal fraction set 2 - 16 samples\nINPUT_DIR2=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/01_fastqc/02_set2/\"\n## Endo 10X Vascular and Parenchymal fraction set 3 - 40 samples\nINPUT_DIR3=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/01_fastqc/03_set3/\"\n\nmultiqc -o $OUTPUT_DIR\"01_set1_reads\" \\\n--filename \"fastqc_endo_10X_set1_reads\" \\\n--title \"FastQC endo 10X set1 reads\" \\\n--cl_config \"fastqc_config: { fastqc_theoretical_gc: hg38_txome }\" \\\n--module fastqc \\\n--force \\\n--interactive \\\n$INPUT_DIR\"\"*_R[1-2]_*_fastqc.zip\n\nmultiqc -o $OUTPUT_DIR\"01_set1_index\" \\\n--filename \"fastqc_endo_10X_set1_index\" \\\n--title \"FastQC endo 10X set1 index\" \\\n--cl_config \"fastqc_config: { fastqc_theoretical_gc: hg38_txome }\" \\\n--module fastqc \\\n--force \\\n--interactive \\\n$INPUT_DIR\"\"*_I[1-2]_*_fastqc.zip\n\nmultiqc -o $OUTPUT_DIR\"02_set2_reads\" \\\n--filename \"fastqc_endo_10X_set2_reads\" \\\n--title \"FastQC endo 10X set2 reads\" \\\n--cl_config \"fastqc_config: { fastqc_theoretical_gc: hg38_txome }\" \\\n--module fastqc \\\n--force \\\n--interactive \\\n$INPUT_DIR2\"\"*_R[1-2]_*_fastqc.zip\n\nmultiqc -o $OUTPUT_DIR\"02_set2_index\" \\\n--filename \"fastqc_endo_10X_set2_index\" \\\n--title \"FastQC endo 10X set2 index\" \\\n--cl_config \"fastqc_config: { fastqc_theoretical_gc: hg38_txome }\" \\\n--module fastqc \\\n--force \\\n--interactive \\\n$INPUT_DIR2\"\"*_I[1-2]_*_fastqc.zip\n\nmultiqc -o $OUTPUT_DIR\"03_set3_reads\" \\\n--filename \"fastqc_endo_10X_set3_reads\" \\\n--title \"FastQC endo 10X set3 reads\" \\\n--cl_config \"fastqc_config: { fastqc_theoretical_gc: hg38_txome }\" \\\n--module fastqc \\\n--force \\\n--interactive \\\n$INPUT_DIR3\"\"*_R[1-2]_*_fastqc.zip\n\nmultiqc -o $OUTPUT_DIR\"02_set3_index\" \\\n--filename \"fastqc_endo_10X_set3_index\" \\\n--title \"FastQC endo 10X set3 index\" \\\n--cl_config \"fastqc_config: { fastqc_theoretical_gc: hg38_txome }\" \\\n--module fastqc \\\n--force \\\n--interactive \\\n$INPUT_DIR3\"\"*_I[1-2]_*_fastqc.zip\n\necho -e \"\\n*****************************************************************\"\necho \"Finished at: \"`date`\necho \"*****************************************************************\""
  },
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/03_generate_cellranger_reference.html",
    "href": "04_data_analysis/001_snrnaseq_analysis/03_generate_cellranger_reference.html",
    "title": "Generate cellranger reference",
    "section": "",
    "text": "In order to run the cellranger pipeline one needs a reference genome for it to align to. 10X do provide a human reference, but it’s rather old at time of writing, so here we’ll generate a more recent one.\nNote that the initial download of the reference files are to be done on the login node. I’ll save them in the shared Webber dir on gluster (/gluster/dri02/rdscw/shared/webber/reference_genomes) in case others want to use it.\n\nCode#!/bin/bash\n\n#SBATCH -p c_highmem_dri1   ###c_highmem_dri1 ## dev, compute, htc, highmem\n#SBATCH --job-name=cellranger_ref_gen_bbb\n#SBATCH --ntasks=40\n#SBATCH --ntasks-per-node=40\n#### SBATCH --mem-per-cpu=30000 # memory limit per core\n#SBATCH --mem=360G # memory limit per compute node for the job\n#SBATCH --time=3-00:00 # maximum job time in D-HH:MM\n#SBATCH --account=scw1329\n#SBATCH -o /scratch/c.mpmgb/hawk_output/%x_out_%J.txt\n#SBATCH -e /scratch/c.mpmgb/hawk_output/%x_err_%J.txt\n#SBATCH --mail-user Bernardo-HarringtonG@cardiff.ac.uk # email on fail\n#SBATCH --mail-type END,FAIL\n\necho \"*****************************************************************\"\necho \"job ID: \"$SLURM_JOBID\necho \"job name: \"$SLURM_JOB_NAME\necho \"Run on host: \"`hostname`\necho \"Number of threads (nproc): \"`nproc`\necho \"Total memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 1p`\necho \"Used memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 2p`\necho \"Free memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 3p`\necho \"Username: \"`whoami`\necho \"Started at: \"`date`\necho -e \"*****************************************************************\\n\"\n\n#-----------------------------------------------------------------------\n\n## code from Cell Ranger (CR) website\n## modified to retrieve GRCh38 genome build from specific ensembl release\n## the default CR reference from July 2020 (refdata-gex-GRCh38-2020-A.tar.gz) is based on ensembl v98/Gencode v32\n## https://support.10xgenomics.com/single-cell-gene-expression/software/release-notes/build\n##\n## NOTE: run first download part on login node\n## pre-processing and cellranger mkref on compute node\n\n#-----------------------------------------------------------------------\n\n## CR v7.1.0\nCELL_RANGER=\"/scratch/c.mpmgb/tools/cellranger-7.1.0/bin/cellranger\"\n\n## which ensembl and gencode version\nENSEMBL_VER=\"109\"\nGENCODE_VER=\"43\"\n\n## store reference data\nREF_DIR=\"/gluster/dri02/rdscw/shared/webber/reference_genomes\"\ncd $REF_DIR\n\n# Genome metadata\ngenome=\"GRCh38\"\nversion=\"2023_\"${ENSEMBL_VER}\n\n# Set up source and build directories\n## need to update build dir!\nbuild=\"GRCh38_2023_ensembl\"${ENSEMBL_VER}\nmkdir -p \"$build\"\n\n# Download source files if they do not exist in reference_sources/ folder\nsource=\"reference_sources_ensembl\"${ENSEMBL_VER}\nmkdir -p \"$source\"\n\nfasta_url=\"http://ftp.ensembl.org/pub/release-\"${ENSEMBL_VER}\"/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz\"\nfasta_in=\"${source}/Homo_sapiens.GRCh38.dna.primary_assembly.fa\"\ngtf_url=\"http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_\"${GENCODE_VER}\"/gencode.v\"${GENCODE_VER}\".primary_assembly.annotation.gtf.gz\"\ngtf_in=\"${source}/gencode.v\"${GENCODE_VER}\".primary_assembly.annotation.gtf\"\n\n#-----------------------------------------------------------------------\n## on login node\n\nif [ ! -f \"$fasta_in\" ]; then\n    curl -sS \"$fasta_url\" | zcat > \"$fasta_in\"\nfi\nif [ ! -f \"$gtf_in\" ]; then\n    curl -sS \"$gtf_url\" | zcat > \"$gtf_in\"\nfi\n\n#-----------------------------------------------------------------------\n## on compute node\n\n## compute node dir\nCOM_DIR=\"/scratch/c.mpmgb/blood-brain-barrier-in-ad/03_data/990_processed_data/001_snrnaseq/03_cellranger_reference\"\ncd $COM_DIR\n\n# Modify sequence headers in the Ensembl FASTA to match the file\n# \"GRCh38.primary_assembly.genome.fa\" from GENCODE. Unplaced and unlocalized\n# sequences such as \"KI270728.1\" have the same names in both versions.\n#\n# Input FASTA:\n#   >1 dna:chromosome chromosome:GRCh38:1:1:248956422:1 REF\n#\n# Output FASTA:\n#   >chr1 1\nfasta_modified=\"$build/$(basename \"$fasta_in\").modified\"\n# sed commands:\n# 1. Replace metadata after space with original contig name, as in GENCODE\n# 2. Add \"chr\" to names of autosomes and sex chromosomes\n# 3. Handle the mitochrondrial chromosome\ncat \"$fasta_in\" \\\n    | sed -E 's/^>(\\S+).*/>\\1 \\1/' \\\n    | sed -E 's/^>([0-9]+|[XY]) />chr\\1 /' \\\n    | sed -E 's/^>MT />chrM /' \\\n    > \"$fasta_modified\"\n\n\n# Remove version suffix from transcript, gene, and exon IDs in order to match\n# previous Cell Ranger reference packages\n#\n# Input GTF:\n#     ... gene_id \"ENSG00000223972.5\"; ...\n# Output GTF:\n#     ... gene_id \"ENSG00000223972\"; gene_version \"5\"; ...\ngtf_modified=\"$build/$(basename \"$gtf_in\").modified\"\n# Pattern matches Ensembl gene, transcript, and exon IDs for human or mouse:\nID=\"(ENS(MUS)?[GTE][0-9]+)\\.([0-9]+)\"\ncat \"$gtf_in\" \\\n    | sed -E 's/gene_id \"'\"$ID\"'\";/gene_id \"\\1\"; gene_version \"\\3\";/' \\\n    | sed -E 's/transcript_id \"'\"$ID\"'\";/transcript_id \"\\1\"; transcript_version \"\\3\";/' \\\n    | sed -E 's/exon_id \"'\"$ID\"'\";/exon_id \"\\1\"; exon_version \"\\3\";/' \\\n    > \"$gtf_modified\"\n\n\n# Define string patterns for GTF tags\n# NOTES:\n# - Since GENCODE release 31/M22 (Ensembl 97), the \"lincRNA\" and \"antisense\"\n#   biotypes are part of a more generic \"lncRNA\" biotype.\n# - These filters are relevant only to GTF files from GENCODE. The GTFs from\n#   Ensembl release 98 have the following differences:\n#   - The names \"gene_biotype\" and \"transcript_biotype\" are used instead of\n#     \"gene_type\" and \"transcript_type\".\n#   - Readthrough transcripts are present but are not marked with the\n#     \"readthrough_transcript\" tag.\n#   - Only the X chromosome versions of genes in the pseudoautosomal regions\n#     are present, so there is no \"PAR\" tag.\nBIOTYPE_PATTERN=\\\n\"(protein_coding|lncRNA|\\\nIG_C_gene|IG_D_gene|IG_J_gene|IG_LV_gene|IG_V_gene|\\\nIG_V_pseudogene|IG_J_pseudogene|IG_C_pseudogene|\\\nTR_C_gene|TR_D_gene|TR_J_gene|TR_V_gene|\\\nTR_V_pseudogene|TR_J_pseudogene)\"\nGENE_PATTERN=\"gene_type \\\"${BIOTYPE_PATTERN}\\\"\"\nTX_PATTERN=\"transcript_type \\\"${BIOTYPE_PATTERN}\\\"\"\nREADTHROUGH_PATTERN=\"tag \\\"readthrough_transcript\\\"\"\nPAR_PATTERN=\"tag \\\"PAR\\\"\"\n\n\n# Construct the gene ID allowlist. We filter the list of all transcripts\n# based on these criteria:\n#   - allowable gene_type (biotype)\n#   - allowable transcript_type (biotype)\n#   - no \"PAR\" tag (only present for Y chromosome PAR)\n#   - no \"readthrough_transcript\" tag\n# We then collect the list of gene IDs that have at least one associated\n# transcript passing the filters.\ncat \"$gtf_modified\" \\\n    | awk '$3 == \"transcript\"' \\\n    | grep -E \"$GENE_PATTERN\" \\\n    | grep -E \"$TX_PATTERN\" \\\n    | grep -Ev \"$READTHROUGH_PATTERN\" \\\n    | grep -Ev \"$PAR_PATTERN\" \\\n    | sed -E 's/.*(gene_id \"[^\"]+\").*/\\1/' \\\n    | sort \\\n    | uniq \\\n    > \"${build}/gene_allowlist\"\n\n\necho \"Filter GTF...\"\n\n# Filter the GTF file based on the gene allowlist\ngtf_filtered=\"${build}/$(basename \"$gtf_in\").filtered\"\n# Copy header lines beginning with \"#\"\ngrep -E \"^#\" \"$gtf_modified\" > \"$gtf_filtered\"\n# Filter to the gene allowlist\ngrep -Ff \"${build}/gene_allowlist\" \"$gtf_modified\" \\\n    >> \"$gtf_filtered\"\n    \n    \necho \"Run Cell Ranger mkref...\"  \n\n## Create reference package\n$CELL_RANGER mkref \\\n--ref-version=\"$version\" \\\n--genome=\"$genome\" \\\n--fasta=\"$fasta_modified\" \\\n--genes=\"$gtf_filtered\" \\\n--memgb=250 \\\n--nthreads=40"
  },
  {
    "objectID": "04_data_analysis/001_snrnaseq_analysis/04_cellranger_count.html",
    "href": "04_data_analysis/001_snrnaseq_analysis/04_cellranger_count.html",
    "title": "Generate cellranger reference",
    "section": "",
    "text": "In order to run the cellranger pipeline one needs a reference genome for it to align to. 10X do provide a human reference, but it’s rather old at time of writing, so here we’ll generate a more recent one.\nSet 1 contains the first 12 donors, 24 samples (12x P - parenchymal and 12x V - vascular fraction), which are independently sequenced of Set_2 (the remaining 16 samples from 8 donors). The sequencing was performed for Set_1 initially in Oxford, but there were some issues with index hopping and cleaning the data did not seem to work too well. So Set_2 was re-sequenced in Cardiff and the folder is: 211008_A00748_0157_AHT7TJDSX2_fastq_L2_3_4\nFor Set_2 the data was sequenced initially on one Illumina lane, but then more lanes were added for better coverage. So the FASTQ files across the 4 subdirs need to be combined as input for one sample. I think there were a couple of corner cases for those samples, one sample was of lower quality and not sequenced again, and one extra run of another sample basically had just one read. I think the script to run CellRanger for Set_2 should mention this and deal with it.\n\nCode#!/bin/bash\n\n#SBATCH -p c_vhighmem_dri1 ## dev, compute, htc, highmem\n#SBATCH --job-name=CR_S1\n#SBATCH --ntasks=40\n#SBATCH --ntasks-per-node=40\n#SBATCH --array=1-24%2\n##### #SBATCH --mem-per-cpu=8000 # memory limit per core\n#SBATCH --mem=740G # memory limit per compute node for the job\n#SBATCH --time=3-00:00 # maximum job time in D-HH:MM\n#SBATCH --account=scw1329\n#SBATCH -o /scratch/c.mpmgb/hawk_output/%x_out_%A_%a_%J.txt\n#SBATCH -e /scratch/c.mpmgb/hawk_output/%x_err_%A_%a_%J.txt\n#SBATCH --mail-user Bernardo-HarringtonG@cardiff.ac.uk # email on fail\n#SBATCH --mail-type END,FAIL\n\necho \"*****************************************************************\"\necho \"All jobs in this array have:\"\necho \"- SLURM_ARRAY_JOB_ID: ${SLURM_ARRAY_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_COUNT: ${SLURM_ARRAY_TASK_COUNT}\"\necho \"- SLURM_ARRAY_TASK_MIN: ${SLURM_ARRAY_TASK_MIN}\"\necho \"- SLURM_ARRAY_TASK_MAX: ${SLURM_ARRAY_TASK_MAX}\"\necho \"This job in the array has:\"\necho \"- SLURM_JOB_ID: ${SLURM_JOB_ID}\"\necho \"- SLURM_ARRAY_TASK_ID: ${SLURM_ARRAY_TASK_ID}\"\necho \"Run on host: \"`hostname`\necho \"Number of threads (nproc): \"`nproc`\necho \"Total memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 1p`\necho \"Used memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 2p`\necho \"Free memory in GB: \"`free -g | grep -oP '\\d+' | sed -n 3p`\necho \"Username: \"`whoami`\necho \"Started at: \"`date`\necho -e \"*****************************************************************\\n\"\n\n#-----------------------------------------------------------------------\n\n## FASTQ files, set 1, 24 samples, sequenced in Cardiff\n## NOTE, R2 length is 150bp, complete length will be used by default\n## alternatively, reads could be trimmed  with Cell Ranger option --r2-length=90\nINPUT_DIR=\"/gluster/dri02/rdscw/shared/webber/Endo_10X/FASTQ/Set_1/211008_A00748_0157_AHT7TJDSX2_fastq_L2_3_4/\"\n\n## results\nOUTPUT_DIR=\"/scratch/c.mpmgb/Endo_10X_main/Analysis/CellRanger_count/CellRanger_count_v701_ensembl_108_set_1_R2_full\"\n\n## original sample IDs, correpond to FASTQ file names\nSAMPLE_ID_FILE=\"/scratch/c.mpmgb/Endo_10X_main/Analysis/Samples_info/samples_set1_IDs.txt\"\n\n## corresponding new sample names to be set by --id\n## NOTE: some samples will be de-swapped, as they were wrongly labelled during library prep in Oxford\nSAMPLE_ID_NEW_FILE=\"/scratch/c.mpmgb/Endo_10X_main/Analysis/Samples_info/samples_set1_IDs_swap.txt\"\n\n## CR executable\n### CELL_RANGER=\"/scratch/c.mpmgb/Tools/CellRanger/cellranger-6.1.1/bin/cellranger\"\nCELL_RANGER=\"/scratch/c.mpmgb/Tools/CellRanger/cellranger-7.0.1/bin/cellranger\"\n\n## CR reference\n## pre-computed and downloaded from CR website as is (refdata-gex-GRCh38-2020-A.tar.gz)\n## based on ensembl v98/gencode v32\n## CR_REF=\"/scratch/c.mpmgb/Tools/CellRanger/CellRanger_references/refdata-gex-GRCh38-2020-A\"\n## updated CR reference based on ensembl v108 (Gencode v42)\n## from get_cellranger_reference.sh\nCR_REF=\"/scratch/c.mpmgb/Tools/CellRanger/CellRanger_references/CR_reference_ensembl/GRCh38\"\n\n#-----------------------------------------------------------------------\n# Cell Ranger count\n\nmkdir -p $OUTPUT_DIR\n\nN=${SLURM_ARRAY_TASK_ID}\n\nSAMPLE_ID=$(cat $SAMPLE_ID_FILE | tail -n+${N} | head -1)\nSAMPLE_ID_NEW=$(cat $SAMPLE_ID_NEW_FILE | tail -n+${N} | head -1)\n\necho \"Input dir: \"$INPUT_DIR\necho \"Sample: \"$SAMPLE_ID\necho \"Sample new: \"$SAMPLE_ID_NEW\n\ncd $OUTPUT_DIR\n\n$CELL_RANGER count --id=$SAMPLE_ID_NEW \\\n--fastqs=$INPUT_DIR \\\n--sample=$SAMPLE_ID \\\n--transcriptome=$CR_REF \\\n--localcores=40 \\\n--localmem=600 \\\n--include-introns=true \\\n--no-bam\n\n## optional:\n## R2 length is longer (150bp) than usually recommended/required (90bp)\n## --r2-length=90\n\necho -e \"\\n*****************************************************************\"\necho \"Finished at: \"`date`\necho \"*****************************************************************\""
  },
  {
    "objectID": "04_data_analysis/990_code_libraries/01_r-packages-used.html",
    "href": "04_data_analysis/990_code_libraries/01_r-packages-used.html",
    "title": "Blood brain barrier in AD",
    "section": "",
    "text": "Here is we install/load all the packages we use in this project.\n\nCode# create library calls for renv\nlibrary_calls <- paste0(\"library(\", c(pkg, pkg_bioconductor), \")\")\nwrite_lines(library_calls, here(\"04_data_analysis/990_code_libraries/02_library-calls-for-renv.R\"))\n\n\n\nCoderm(pkg, pkg_bioconductor, sort_packages)"
  },
  {
    "objectID": "06_dissemination/03_website/01_data-analysis.html",
    "href": "06_dissemination/03_website/01_data-analysis.html",
    "title": "Data Analysis Pipeline",
    "section": "",
    "text": "This section of the site houses the data analysis performed."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BBB in AD",
    "section": "",
    "text": "This is a Quarto website that outlines the analysis pipeline of this project."
  },
  {
    "objectID": "index.html#renv",
    "href": "index.html#renv",
    "title": "BBB in AD",
    "section": "\n1.1 renv",
    "text": "1.1 renv\nNote that the project used renv to manage the R packages used. When you first clone the repo to your local machine, you’ll need to run renv::restore() in R for it to establish all the packages needed."
  },
  {
    "objectID": "index.html#website-execution-caching",
    "href": "index.html#website-execution-caching",
    "title": "BBB in AD",
    "section": "\n1.2 Website execution caching",
    "text": "1.2 Website execution caching\nNote that the website uses caching to save the results of the scripts to the _freeze directory.\nThis is helpful as it allows the website to be built quickly after the first build, but it can be tricky as it will only rerun a given script if it sees a change in that script. So, if you change an earlier script that would alter the inputs of later scripts, it wouldn’t rerun those script as the code hadn’t changed, and so they wouldn’t change on the website.\nIf you run into any issues with this, just delete the _freeze directory and build the website again."
  }
]